{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GATConv, NNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in connectomes\n",
    "test_connectome = pd.read_csv('/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
    "train_connectome = pd.read_csv('/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/widsdatathon2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv')\n",
    "# Read in solutions \n",
    "solutions = pd.read_excel('/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_construct(df, num_regions=200):\n",
    "    graph_list = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        participant_id = row['participant_id']\n",
    "        participant_row = row.values[1:]  # Skip participant ID if present\n",
    "        adj_matrix = np.zeros((num_regions, num_regions))\n",
    "\n",
    "        # Fill adjacency matrix (upper triangle only)\n",
    "        idx = 0\n",
    "        for i in range(num_regions):\n",
    "            for j in range(i + 1, num_regions):\n",
    "                adj_matrix[i, j] = participant_row[idx]\n",
    "                adj_matrix[j, i] = participant_row[idx]\n",
    "                idx += 1\n",
    "\n",
    "        # Extract edge index and weights\n",
    "        i_idx, j_idx = np.triu_indices(num_regions, k=1)\n",
    "        edges = np.stack([i_idx, j_idx], axis=1)\n",
    "        edge_weights = adj_matrix[i_idx, j_idx]\n",
    "\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        edge_index = torch.tensor(edges.T, dtype=torch.long)\n",
    "        edge_attr = torch.tensor(edge_weights, dtype=torch.float).unsqueeze(1)\n",
    "        x = torch.eye(num_regions, dtype=torch.float)\n",
    "\n",
    "        graph_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, num_nodes=num_regions)\n",
    "        graph_data.participant_id = participant_id \n",
    "        # Add to list\n",
    "        graph_list.append(graph_data)\n",
    "\n",
    "    return graph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement \n",
    "train_graph_list = create_graph_construct(train_connectome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with CGNConv\n",
    "class ConnectomeNNGNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_nodes, hidden_dim):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        # nn for conv1: maps edge_attr to [num_edges, num_nodes * hidden_dim]\n",
    "        nn1 = Sequential(Linear(1, 128), ReLU(), Linear(128, num_nodes * hidden_dim))\n",
    "        # nn for conv2: maps edge_attr to [num_edges, hidden_dim * hidden_dim]\n",
    "        nn2 = Sequential(Linear(1, 128), ReLU(), Linear(128, hidden_dim * hidden_dim))\n",
    "        self.conv1 = NNConv(num_nodes, hidden_dim, nn1)\n",
    "        self.conv2 = NNConv(hidden_dim, hidden_dim, nn2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = Sequential(Linear(2 * hidden_dim, 128), ReLU(), Linear(128, 1))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Encoder\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        # Decoder: Predict edge attributes\n",
    "        row, col = edge_index\n",
    "        edge_features = torch.cat([x[row], x[col]], dim=-1)  # Concatenate node embeddings\n",
    "        reconstructed_edge_attr = self.decoder(edge_features)  # [num_edges, 1]\n",
    "        return reconstructed_edge_attr\n",
    "\n",
    "    def loss(self, reconstructed_edge_attr, true_edge_attr):\n",
    "        return F.mse_loss(reconstructed_edge_attr, true_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_graph_list, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "num_nodes = 200\n",
    "hidden_dim = 256\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ConnectomeNNGNN(num_nodes=num_nodes, hidden_dim=hidden_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        reconstructed_edge_attr = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = model.loss(reconstructed_edge_attr, batch.edge_attr)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    \n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/Models/grapg_gnn_ae.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT Autoencoder\n",
    "Using graph_list\n",
    "\n",
    "Head: number to attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "features = train_connectome.drop(columns=['participant_id']).values\n",
    "x = torch.tensor(features, dtype=torch.float32)\n",
    "print(\"x shape:\", x.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with GAT\n",
    "class ConnectomeGNN(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_dim, heads=1):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(num_nodes, hidden_dim, heads=heads, concat=True)\n",
    "        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, concat=True) \n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_dim, 64) \n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch) \n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 200 \n",
    "hidden_dim = 64\n",
    "model = ConnectomeGNN(num_nodes=num_nodes, hidden_dim=hidden_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        emb = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch) \n",
    "        embeddings.append(emb.cpu())  \n",
    "\n",
    "# Combine into one tensor\n",
    "all_embeddings = torch.cat(embeddings, dim=0)  \n",
    "\n",
    "# Get participant ids \n",
    "train_graph_ids = [g.participant_id for g in train_graph_list]\n",
    "\n",
    "gnn_embeddings = pd.DataFrame(all_embeddings.numpy())\n",
    "gnn_embeddings['participant_id'] = train_graph_ids\n",
    "\n",
    "\n",
    "gnn_embeddings_merged = pd.merge(gnn_embeddings, solutions, on='participant_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.enc21 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.enc22 = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.dec1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.dec2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.enc1(x))\n",
    "        mu = self.enc21(h)\n",
    "        logvar = self.enc22(h)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = F.rellu(self.dec1(z))\n",
    "        return torch.sigmoid(self.enc2(h))\n",
    "    \n",
    "    def forward(self, x, input_dim):\n",
    "        mu, logvar = self.encode(x.view(-1, input_dim))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "    def loss_function(recon_x, x, mu, logvar, input_dim):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x.view(-1, input_dim))\n",
    "        KLD = 0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + KLD\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize model, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Batch {batch_idx}, Loss {loss.item() / len(data):.6f}')\n",
    "    print(f'Epoch {epoch}, Avg Loss {train_loss / len(train_loader.dataset):.6f}')\n",
    "\n",
    "# Run for 10 epochs\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

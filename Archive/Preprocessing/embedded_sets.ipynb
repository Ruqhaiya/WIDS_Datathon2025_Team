{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in connectomes\n",
    "test_connectome = pd.read_csv('/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
    "train_connectome = pd.read_csv('/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/widsdatathon2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv')\n",
    "\n",
    "# Read in solutions \n",
    "solutions = pd.read_excel('/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in survey data\n",
    "train_cat_quant = pd.read_csv('/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/Preprocessing/train_cat_quant_imputed.csv')\n",
    "test_cat_quant = pd.read_csv('/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/Preprocessing/test_cat_quant_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>0throw_1thcolumn</th>\n",
       "      <th>0throw_2thcolumn</th>\n",
       "      <th>0throw_3thcolumn</th>\n",
       "      <th>0throw_4thcolumn</th>\n",
       "      <th>0throw_5thcolumn</th>\n",
       "      <th>0throw_6thcolumn</th>\n",
       "      <th>0throw_7thcolumn</th>\n",
       "      <th>0throw_8thcolumn</th>\n",
       "      <th>0throw_9thcolumn</th>\n",
       "      <th>...</th>\n",
       "      <th>195throw_196thcolumn</th>\n",
       "      <th>195throw_197thcolumn</th>\n",
       "      <th>195throw_198thcolumn</th>\n",
       "      <th>195throw_199thcolumn</th>\n",
       "      <th>196throw_197thcolumn</th>\n",
       "      <th>196throw_198thcolumn</th>\n",
       "      <th>196throw_199thcolumn</th>\n",
       "      <th>197throw_198thcolumn</th>\n",
       "      <th>197throw_199thcolumn</th>\n",
       "      <th>198throw_199thcolumn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70z8Q2xdTXM3</td>\n",
       "      <td>0.22293</td>\n",
       "      <td>0.527903</td>\n",
       "      <td>0.429966</td>\n",
       "      <td>0.060457</td>\n",
       "      <td>0.566489</td>\n",
       "      <td>0.315342</td>\n",
       "      <td>0.508408</td>\n",
       "      <td>-0.07829</td>\n",
       "      <td>0.525692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224985</td>\n",
       "      <td>0.397448</td>\n",
       "      <td>0.422966</td>\n",
       "      <td>0.184642</td>\n",
       "      <td>0.305549</td>\n",
       "      <td>0.420349</td>\n",
       "      <td>0.016328</td>\n",
       "      <td>0.561864</td>\n",
       "      <td>0.47117</td>\n",
       "      <td>0.365221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 19901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  0throw_1thcolumn  0throw_2thcolumn  0throw_3thcolumn  \\\n",
       "0   70z8Q2xdTXM3           0.22293          0.527903          0.429966   \n",
       "\n",
       "   0throw_4thcolumn  0throw_5thcolumn  0throw_6thcolumn  0throw_7thcolumn  \\\n",
       "0          0.060457          0.566489          0.315342          0.508408   \n",
       "\n",
       "   0throw_8thcolumn  0throw_9thcolumn  ...  195throw_196thcolumn  \\\n",
       "0          -0.07829          0.525692  ...              0.224985   \n",
       "\n",
       "   195throw_197thcolumn  195throw_198thcolumn  195throw_199thcolumn  \\\n",
       "0              0.397448              0.422966              0.184642   \n",
       "\n",
       "   196throw_197thcolumn  196throw_198thcolumn  196throw_199thcolumn  \\\n",
       "0              0.305549              0.420349              0.016328   \n",
       "\n",
       "   197throw_198thcolumn  197throw_199thcolumn  198throw_199thcolumn  \n",
       "0              0.561864               0.47117              0.365221  \n",
       "\n",
       "[1 rows x 19901 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_connectome.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Graph Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to define the NonGraphDAE again to load trained model \n",
    "\n",
    "# Define NonGraphDAE class\n",
    "class NonGraphAE(nn.Module):\n",
    "    def __init__(self, input_dim=19900, hidden_dim=256, latent_dim=512, dropout=0.2):\n",
    "        super(NonGraphAE, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Encoder layers\n",
    "        self.enc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.enc2 = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.dec1 = nn.Linear(latent_dim, hidden_dim) \n",
    "        self.dec2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.relu(self.enc1(x))\n",
    "        x = self.enc2(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x = self.relu(self.dec1(z))\n",
    "        x = self.dec2(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome data \n",
    "ids = train_connectome['participant_id']\n",
    "connectome_features = train_connectome.iloc[:, 1:].values\n",
    "\n",
    "# Convert to tensor\n",
    "X = torch.tensor(connectome_features, dtype=torch.float32)\n",
    "\n",
    "# Load autoencoder\n",
    "autoencoder = torch.load('/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/Models/nongraph_autoencoder.pth', weights_only=False)\n",
    "\n",
    "# Set to evaluation mode\n",
    "autoencoder.eval()\n",
    "\n",
    "# Get latent reps\n",
    "with torch.no_grad():\n",
    "    _, z = autoencoder(X)  # z is the latent embeddings\n",
    "    encoded_features = z.numpy()\n",
    "\n",
    "# Save encoded features with IDs\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=[f\"latent_{i}\" for i in range(encoded_features.shape[1])])\n",
    "encoded_df[\"participant_id\"] = ids\n",
    "encoded_df = encoded_df[['participant_id'] + [col for col in encoded_df.columns if col != 'participant_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>latent_0</th>\n",
       "      <th>latent_1</th>\n",
       "      <th>latent_2</th>\n",
       "      <th>latent_3</th>\n",
       "      <th>latent_4</th>\n",
       "      <th>latent_5</th>\n",
       "      <th>latent_6</th>\n",
       "      <th>latent_7</th>\n",
       "      <th>latent_8</th>\n",
       "      <th>...</th>\n",
       "      <th>latent_502</th>\n",
       "      <th>latent_503</th>\n",
       "      <th>latent_504</th>\n",
       "      <th>latent_505</th>\n",
       "      <th>latent_506</th>\n",
       "      <th>latent_507</th>\n",
       "      <th>latent_508</th>\n",
       "      <th>latent_509</th>\n",
       "      <th>latent_510</th>\n",
       "      <th>latent_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70z8Q2xdTXM3</td>\n",
       "      <td>0.410976</td>\n",
       "      <td>-0.501845</td>\n",
       "      <td>-0.364146</td>\n",
       "      <td>-0.491903</td>\n",
       "      <td>0.393063</td>\n",
       "      <td>0.252061</td>\n",
       "      <td>-1.805321</td>\n",
       "      <td>-0.230074</td>\n",
       "      <td>0.169664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184198</td>\n",
       "      <td>0.609233</td>\n",
       "      <td>1.180916</td>\n",
       "      <td>-0.879422</td>\n",
       "      <td>-0.972005</td>\n",
       "      <td>-1.547123</td>\n",
       "      <td>-0.123295</td>\n",
       "      <td>-0.290636</td>\n",
       "      <td>0.592719</td>\n",
       "      <td>-1.227824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHWymJu6zNZi</td>\n",
       "      <td>0.222915</td>\n",
       "      <td>-0.410652</td>\n",
       "      <td>-0.118329</td>\n",
       "      <td>-0.074499</td>\n",
       "      <td>0.187898</td>\n",
       "      <td>-0.457596</td>\n",
       "      <td>-0.914698</td>\n",
       "      <td>0.064583</td>\n",
       "      <td>-0.498138</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.553056</td>\n",
       "      <td>-0.078315</td>\n",
       "      <td>0.460481</td>\n",
       "      <td>0.364299</td>\n",
       "      <td>0.431604</td>\n",
       "      <td>-0.076219</td>\n",
       "      <td>0.672366</td>\n",
       "      <td>0.059622</td>\n",
       "      <td>-0.239692</td>\n",
       "      <td>-0.398499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4PAQp1M6EyAo</td>\n",
       "      <td>0.746281</td>\n",
       "      <td>0.570709</td>\n",
       "      <td>-0.108126</td>\n",
       "      <td>0.026869</td>\n",
       "      <td>-0.682994</td>\n",
       "      <td>-0.268827</td>\n",
       "      <td>-1.313621</td>\n",
       "      <td>-0.651664</td>\n",
       "      <td>-0.116300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044046</td>\n",
       "      <td>0.331892</td>\n",
       "      <td>-0.121569</td>\n",
       "      <td>0.188966</td>\n",
       "      <td>1.127963</td>\n",
       "      <td>-0.260610</td>\n",
       "      <td>1.400629</td>\n",
       "      <td>1.148817</td>\n",
       "      <td>0.307426</td>\n",
       "      <td>-0.802827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obEacy4Of68I</td>\n",
       "      <td>-0.103012</td>\n",
       "      <td>-0.437822</td>\n",
       "      <td>0.132941</td>\n",
       "      <td>-0.062930</td>\n",
       "      <td>-0.225961</td>\n",
       "      <td>-0.258818</td>\n",
       "      <td>0.495031</td>\n",
       "      <td>-0.261689</td>\n",
       "      <td>1.457125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296552</td>\n",
       "      <td>0.191983</td>\n",
       "      <td>0.263804</td>\n",
       "      <td>-0.448022</td>\n",
       "      <td>0.006136</td>\n",
       "      <td>-1.076978</td>\n",
       "      <td>0.745718</td>\n",
       "      <td>-0.082977</td>\n",
       "      <td>1.639096</td>\n",
       "      <td>-0.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s7WzzDcmDOhF</td>\n",
       "      <td>0.727864</td>\n",
       "      <td>-0.362274</td>\n",
       "      <td>-0.416239</td>\n",
       "      <td>0.214545</td>\n",
       "      <td>0.544973</td>\n",
       "      <td>0.524552</td>\n",
       "      <td>-2.167723</td>\n",
       "      <td>-0.185471</td>\n",
       "      <td>0.059395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206027</td>\n",
       "      <td>0.800041</td>\n",
       "      <td>-0.495047</td>\n",
       "      <td>1.444625</td>\n",
       "      <td>-1.412053</td>\n",
       "      <td>-0.399675</td>\n",
       "      <td>0.357171</td>\n",
       "      <td>0.081166</td>\n",
       "      <td>-1.454923</td>\n",
       "      <td>0.532057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  latent_0  latent_1  latent_2  latent_3  latent_4  latent_5  \\\n",
       "0   70z8Q2xdTXM3  0.410976 -0.501845 -0.364146 -0.491903  0.393063  0.252061   \n",
       "1   WHWymJu6zNZi  0.222915 -0.410652 -0.118329 -0.074499  0.187898 -0.457596   \n",
       "2   4PAQp1M6EyAo  0.746281  0.570709 -0.108126  0.026869 -0.682994 -0.268827   \n",
       "3   obEacy4Of68I -0.103012 -0.437822  0.132941 -0.062930 -0.225961 -0.258818   \n",
       "4   s7WzzDcmDOhF  0.727864 -0.362274 -0.416239  0.214545  0.544973  0.524552   \n",
       "\n",
       "   latent_6  latent_7  latent_8  ...  latent_502  latent_503  latent_504  \\\n",
       "0 -1.805321 -0.230074  0.169664  ...   -0.184198    0.609233    1.180916   \n",
       "1 -0.914698  0.064583 -0.498138  ...   -0.553056   -0.078315    0.460481   \n",
       "2 -1.313621 -0.651664 -0.116300  ...    0.044046    0.331892   -0.121569   \n",
       "3  0.495031 -0.261689  1.457125  ...   -0.296552    0.191983    0.263804   \n",
       "4 -2.167723 -0.185471  0.059395  ...    0.206027    0.800041   -0.495047   \n",
       "\n",
       "   latent_505  latent_506  latent_507  latent_508  latent_509  latent_510  \\\n",
       "0   -0.879422   -0.972005   -1.547123   -0.123295   -0.290636    0.592719   \n",
       "1    0.364299    0.431604   -0.076219    0.672366    0.059622   -0.239692   \n",
       "2    0.188966    1.127963   -0.260610    1.400629    1.148817    0.307426   \n",
       "3   -0.448022    0.006136   -1.076978    0.745718   -0.082977    1.639096   \n",
       "4    1.444625   -1.412053   -0.399675    0.357171    0.081166   -1.454923   \n",
       "\n",
       "   latent_511  \n",
       "0   -1.227824  \n",
       "1   -0.398499  \n",
       "2   -0.802827  \n",
       "3   -0.550482  \n",
       "4    0.532057  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df_merged = encoded_df.merge(solutions, on='participant_id', how='left')\n",
    "encoded_df_cat_quant_merged = encoded_df_merged.merge(train_cat_quant, on='participant_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df_cat_quant_merged.to_csv('merged_ae_encoded_cat_quant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions['outcome'] = np.select(\n",
    "    [\n",
    "        (solutions['ADHD_Outcome'] == 1) & (solutions['Sex_F'] == 1),  # ADHD and female\n",
    "        (solutions['ADHD_Outcome'] == 0) & (solutions['Sex_F'] == 1),  # No ADHD and female\n",
    "        (solutions['ADHD_Outcome'] == 1) & (solutions['Sex_F'] == 0),  # ADHD and male\n",
    "        (solutions['ADHD_Outcome'] == 0) & (solutions['Sex_F'] == 0),  # No ADHD and male\n",
    "    ],\n",
    "    ['adhd_f', 'noadhd_f', 'adhd_m', 'noadhd_m'], \n",
    "    default=np.nan  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Non Graph Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonGraphDAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, dropout=0.2):\n",
    "        \n",
    "        super(NonGraphDAE, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Encoder layer: learns node embeddings, compressed node into latent_dim\n",
    "        self.enc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.enc2 = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder layer: Fully connected layers to predict edge weights between node pairs\n",
    "        self.dec1 = nn.Linear(latent_dim, hidden_dim) \n",
    "        self.dec2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU() # non-linearity\n",
    "\n",
    "    def add_noise(self, x, noise_factor=0.05):\n",
    "        \n",
    "        noisy_x = x.clone() # Clone to not modify original\n",
    "        mask = torch.rand(x.size(), device = x.device) > self.dropout # Randomly drop edge weights\n",
    "        noise = torch.randn_like(x) * noise_factor\n",
    "        noisy_x[mask] += noise[mask]\n",
    "\n",
    "        return noisy_x\n",
    "    \n",
    "    # Encoder\n",
    "    def encode(self, x):\n",
    "\n",
    "        x = self.relu(self.enc1(x))# Encode the graph to latent node embeddings using GCN layers\n",
    "        x = self.enc2(x)\n",
    "        return x\n",
    "    \n",
    "    # Decoder\n",
    "    def decode(self, z):\n",
    "\n",
    "        x = self.relu(self.dec1(z))\n",
    "        x = self.dec2(x)\n",
    "        return x\n",
    "    \n",
    "    # Combines all steps: noise, encode, and decode\n",
    "    # Returns reconstructed edge weights nad z a tensor object of latent node embeddings\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Add noise \n",
    "        noisy_x = self.add_noise(x) if self.training else x\n",
    "        # Encode noisy graph to latent embeddings\n",
    "        z = self.encode(noisy_x)\n",
    "        # Decode to reconstruct clean edge weights\n",
    "        recon_x = self.decode(z)\n",
    "\n",
    "        return recon_x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/Models/nongraph_dae.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m), weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Set to evaluation mode\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Get latent reps\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "# Connectome data \n",
    "ids = train_connectome['participant_id']\n",
    "connectome_features = train_connectome.iloc[:, 1:].values\n",
    "\n",
    "# Convert to tensor\n",
    "X = torch.tensor(connectome_features, dtype=torch.float32)\n",
    "\n",
    "# Load autoencoder\n",
    "autoencoder = torch.load('/Users/rubyc/Desktop/Datathon/WIDS_Datathon2025_Team/Archive/Models/nongraph_dae.pth', map_location=torch.device('cpu'), weights_only=False)\n",
    "\n",
    "# Set to evaluation mode\n",
    "autoencoder.eval()\n",
    "\n",
    "# Get latent reps\n",
    "with torch.no_grad():\n",
    "    _, z = autoencoder(X)  # z is the latent embeddings\n",
    "    encoded_features = z.numpy()\n",
    "\n",
    "# Save encoded features with IDs\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=[f\"latent_{i}\" for i in range(encoded_features.shape[1])])\n",
    "encoded_df[\"participant_id\"] = ids\n",
    "encoded_df = encoded_df[['participant_id'] + [col for col in encoded_df.columns if col != 'participant_id']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
